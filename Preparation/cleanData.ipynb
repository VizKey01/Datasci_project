{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "### **Cleansing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libraries and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crossref_papers.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix HTML tag in title and abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove HTML tags and decode HTML entities\n",
    "def clean_html(text):\n",
    "    if isinstance(text, str):  # Check if the text is a string\n",
    "        # Decode HTML entities\n",
    "        text = html.unescape(text)\n",
    "        # Remove all HTML tags\n",
    "        return re.sub(r'<[^>]*>', '', text).strip()  # Remove anything between <>\n",
    "    return text  # If it's not a string, return as is\n",
    "\n",
    "# Apply cleaning to the 'title' and 'abstract' columns\n",
    "df['title'] = df['title'].apply(clean_html)\n",
    "df['abstract'] = df['abstract'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix title and abstract string error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove paragraphs and line breaks\n",
    "def clean_paragraphs(text):\n",
    "    # Replace line breaks with a single space\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    # Remove extra spaces between words\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply the clean_abstract function to the 'abstract' column\n",
    "df['title'] = df['title'].apply(clean_paragraphs)\n",
    "df['abstract'] = df['abstract'].apply(clean_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut off the year that under 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the year is less than or equal to 2019\n",
    "df_deleted = df[df['year'] <= 2019]\n",
    "\n",
    "# Filter rows where the year is greater than 2019\n",
    "df_remaining = df[df['year'] > 2019]\n",
    "\n",
    "# Display the count of deleted and remaining rows\n",
    "print(f\"Number of Rows Deleted: {len(df_deleted)}\")\n",
    "print(f\"Number of Rows Remaining: {len(df_remaining)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Abstract Format that start with text Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove 'Abstract' or 'abstract' from the start of the text\n",
    "def remove_abstract(text):\n",
    "    if isinstance(text, str):  # Check if the text is a string\n",
    "        # Check if the text starts with \"Abstract\" or \"abstract\"\n",
    "        if text.lower().startswith('abstract'):\n",
    "            # Remove the word 'Abstract' (or 'abstract') from the start and any following space\n",
    "            text = text[8:].lstrip()  # Start from the 9th character to remove 'Abstract' + space\n",
    "    return text\n",
    "\n",
    "# Apply the remove_abstract function to the 'abstract' column\n",
    "df_remaining['abstract'] = df_remaining['abstract'].apply(remove_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remaining = df_remaining.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check affiliation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remaining = df_remaining[~df_remaining['affiliation'].str.lower().isin(['independent researcher', 'independent consultant', 'independent'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Cleaned Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the remaining rows to a new CSV file\n",
    "df_remaining.to_csv('cleaned_file.csv', index=False)\n",
    "print(\"Cleaning done! Final file saved as 'cleaned_file.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make only affiliations for find latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned data file\n",
    "df = pd.read_csv('cleaned_file.csv')\n",
    "\n",
    "# Extract unique affiliations\n",
    "df = df['affiliation'].drop_duplicates()\n",
    "df = pd.DataFrame(df)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format affiliation to latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geolocator setup\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# Function to get latitude and longitude\n",
    "def get_coordinates(x):\n",
    "    try:\n",
    "        location = geolocator.geocode(x)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching coordinates for {x}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to the affiliation column\n",
    "df['latitude'], df['longitude'] = zip(*df['affiliation'].apply(get_coordinates))\n",
    "\n",
    "# Drop rows with NaN values in latitude or longitude\n",
    "df_cleaned = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "df_cleaned.to_csv('affiliations_with_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge affiliation_with_coordinates to the cleaned_file to get final result for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "cleaned_file = pd.read_csv('cleaned_file.csv')\n",
    "merged_file = pd.read_csv('affiliations_with_coordinates.csv')\n",
    "\n",
    "# Merge the two DataFrames on the 'affiliation' column\n",
    "final_df = pd.merge(cleaned_file, merged_file, on='affiliation', how='left')\n",
    "\n",
    "# Drop rows where latitude or longitude is missing\n",
    "final_df = final_df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Save the merged and cleaned DataFrame to a new CSV file\n",
    "final_df.to_csv('Final.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('Final.csv')\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
