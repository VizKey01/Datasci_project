{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "data = pd.read_csv('../resources/cleaned_processdata.csv')\n",
    "data['Processed_Abstracts'] = data['Processed_Abstracts'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text data\n",
    "texts = [doc.split() for doc in data['Processed_Abstracts']]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to compute coherence for different topic numbers\n",
    "# def compute_coherence_values(dictionary, corpus, texts, start, stop, step):\n",
    "#     coherence_values = []\n",
    "#     model_list = []\n",
    "#     for num_topics in range(start, stop, step):\n",
    "#         model = gensim.models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=5)\n",
    "#         model_list.append(model)\n",
    "#         coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "#         coherence_values.append(coherence_model.get_coherence())\n",
    "#     return model_list, coherence_values\n",
    "\n",
    "# # Define range for topics\n",
    "# start, stop, step = 2, 12, 2  # Adjust range for quicker runtime\n",
    "\n",
    "# # Compute coherence scores\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary, corpus, texts, start, stop, step)\n",
    "\n",
    "# # Plot coherence values\n",
    "# x = range(start, stop, step)\n",
    "# plt.plot(x, coherence_values)\n",
    "# plt.xlabel(\"Number of Topics\")\n",
    "# plt.ylabel(\"Coherence Score\")\n",
    "# plt.title(\"Optimal Number of Topics\")\n",
    "# plt.show()\n",
    "\n",
    "# # Find the optimal number of topics\n",
    "# optimal_num_topics = x[coherence_values.index(max(coherence_values))]\n",
    "# optimal_num_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_num_topics = 8\n",
    "\n",
    "# Fit the optimal LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=optimal_num_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "# Get top words for each topic\n",
    "top_words_per_topic = []\n",
    "for topic_id in range(optimal_num_topics):\n",
    "    top_words = lda_model.show_topic(topic_id, topn=10)  # Get top 10 words\n",
    "    top_words_per_topic.append([word for word, _ in top_words])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \"\"Magnetic Treatment Impact on Cell Metabolism in Patient Group Study\"\"\n",
      "Topic 1: \"High-performance carbon materials for energy storage and reaction.\"\n",
      "Topic 2: \"\"Adsorption Properties of Carbon-based Composites\"\"\n",
      "Topic 3: \"\"CO2 Concentration and Emissions in Water\"\"\n",
      "Topic 4: \"Model Development and Evaluation\"\n",
      "Topic 5: \"Soil Carbon and Nitrogen Dynamics in Forest Ecosystems.\"\n",
      "Topic 6: \"\"Low-Carbon Emission Development in China: Electrochemical Model Study\"\"\n",
      "Topic 7: \"\"Reducing Carbon Emissions through Sustainable Energy Production and Use\"\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Your API Key (replace with your actual key)\n",
    "API_URL = \"https://api.opentyphoon.ai/v1/chat/completions\"\n",
    "\n",
    "# Define topics\n",
    "# topics = [\n",
    "#     [\"carbon\", \"co2\", \"energy\", \"climate\", \"gas\", \"production\", \"emissions\", \"dioxide\", \"change\", \"emission\"],\n",
    "#     [\"energy\", \"systems\", \"carbon\", \"system\", \"oil\", \"study\", \"bed\", \"water\", \"palm\", \"technologies\"],\n",
    "#     [\"change\", \"climate\", \"waste\", \"rainfall\", \"impacts\", \"study\", \"future\", \"used\", \"surface\", \"temperature\"],\n",
    "#     [\"carbon\", \"environmental\", \"study\", \"climate\", \"change\", \"emission\", \"emissions\", \"energy\", \"used\", \"development\"],\n",
    "#     [\"co2\", \"oil\", \"methanol\", \"process\", \"carbon\", \"using\", \"production\", \"high\", \"gas\", \"capture\"],\n",
    "#     [\"climate\", \"change\", \"water\", \"co2\", \"study\", \"storage\", \"natural\", \"environmental\", \"system\", \"air\"],\n",
    "#     [\"reactor\", \"heat\", \"carbon\", \"climate\", \"results\", \"also\", \"change\", \"different\", \"used\", \"biochar\"],\n",
    "#     [\"energy\", \"co2\", \"model\", \"climate\", \"study\", \"emissions\", \"change\", \"effect\", \"growth\", \"consumption\"]\n",
    "# ]\n",
    "\n",
    "# Function to generate topic labels using Typhoon API\n",
    "def generate_topic_label_typhoon(topic_keywords):\n",
    "    # Refined prompt for descriptive and concise topic labels\n",
    "    prompt = (\n",
    "        f\"Based on the following keywords, create a concise, descriptive label that summarizes the main topic: \"\n",
    "        f\"{', '.join(topic_keywords)}.\"\n",
    "    )\n",
    "\n",
    "    # Construct the payload\n",
    "    payload = {\n",
    "        \"model\": \"typhoon-v1.5x-70b-instruct\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.95,\n",
    "        \"repetition_penalty\": 1.05,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    # Send the request to the Typhoon API\n",
    "    response = requests.post(\n",
    "        API_URL,\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "        },\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        label = response_data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return label\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Generate and refine labels for all topics\n",
    "topic_labels = [generate_topic_label_typhoon(words) for words in top_words_per_topic]\n",
    "\n",
    "# Print the refined labels in the desired format\n",
    "for idx, label in enumerate(topic_labels):\n",
    "    print(f\"Topic {idx}: \\\"{label}\\\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'topicdata2.csv'. Fetched 8 results.\n"
     ]
    }
   ],
   "source": [
    "# cutting topic_labels text \"\"\n",
    "\n",
    "topic_labels = [label.replace('\"', '') for label in topic_labels]\n",
    "topic_labels\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(topic_labels)\n",
    "df.to_csv('../resources/topicdata2.csv', index=False, encoding='utf-8')\n",
    "print(f\"Data saved to 'topicdata2.csv'. Fetched {len(df)} results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'cleaned_topicdata.csv'. Fetched 8 results.\n"
     ]
    }
   ],
   "source": [
    "# top_words_per_topic\n",
    "\n",
    "# data.head()\n",
    "df = pd.DataFrame(top_words_per_topic)\n",
    "# Save to CSV\n",
    "if not df.empty:\n",
    "    df.to_csv('../resources/cleaned_topicdata.csv', index=False, encoding='utf-8')\n",
    "    print(f\"Data saved to 'cleaned_topicdata.csv'. Fetched {len(df)} results.\")\n",
    "else:\n",
    "    print(\"No data fetched. Check the scraping process.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
