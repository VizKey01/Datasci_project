{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# read_file and convert type\n",
    "data = pd.read_csv('../resources/cleaned_processdata.csv')\n",
    "data['Processed_Abstracts'] = data['Processed_Abstracts'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text data\n",
    "texts = [doc.split() for doc in data['Processed_Abstracts']]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to compute coherence for different topic numbers\n",
    "# def compute_coherence_values(dictionary, corpus, texts, start, stop, step):\n",
    "#     coherence_values = []\n",
    "#     model_list = []\n",
    "#     for num_topics in range(start, stop, step):\n",
    "#         model = gensim.models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=5)\n",
    "#         model_list.append(model)\n",
    "#         coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "#         coherence_values.append(coherence_model.get_coherence())\n",
    "#     return model_list, coherence_values\n",
    "\n",
    "# # Define range for topics\n",
    "# start, stop, step = 2, 12, 2  # Adjust range for quicker runtime\n",
    "\n",
    "# # Compute coherence scores\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary, corpus, texts, start, stop, step)\n",
    "\n",
    "# # Plot coherence values\n",
    "# x = range(start, stop, step)\n",
    "# plt.plot(x, coherence_values)\n",
    "# plt.xlabel(\"Number of Topics\")\n",
    "# plt.ylabel(\"Coherence Score\")\n",
    "# plt.title(\"Optimal Number of Topics\")\n",
    "# plt.show()\n",
    "\n",
    "# # Find the optimal number of topics\n",
    "# optimal_num_topics = x[coherence_values.index(max(coherence_values))]\n",
    "# optimal_num_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_num_topics = 8\n",
    "\n",
    "# Fit the optimal LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=optimal_num_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "# Get top words for each topic\n",
    "top_words_per_topic = []\n",
    "for topic_id in range(optimal_num_topics):\n",
    "    top_words = lda_model.show_topic(topic_id, topn=10)  # Get top 10 words\n",
    "    top_words_per_topic.append([word for word, _ in top_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automate Topic name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Your API Key (replace with your actual key)\n",
    "API_KEY = \"sk-7EfUfbCz6VIESFu4Nt9qjquhQnhPOvPbKtkZhWC71XTIbuTC\"\n",
    "API_URL = \"https://api.opentyphoon.ai/v1/chat/completions\"\n",
    "\n",
    "# Function to generate topic labels using Typhoon API\n",
    "def generate_topic_label_typhoon(topic_keywords):\n",
    "    # Refined prompt for descriptive and concise topic labels\n",
    "    prompt = (\n",
    "        f\"Based on the following keywords, create a concise, descriptive label that summarizes the main topic: \"\n",
    "        f\"{', '.join(topic_keywords)}.\"\n",
    "    )\n",
    "\n",
    "    # Construct the payload\n",
    "    payload = {\n",
    "        \"model\": \"typhoon-v1.5x-70b-instruct\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.95,\n",
    "        \"repetition_penalty\": 1.05,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    # Send the request to the Typhoon API\n",
    "    response = requests.post(\n",
    "        API_URL,\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "        },\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        label = response_data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return label\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Generate and refine labels for all topics\n",
    "topic_labels = [generate_topic_label_typhoon(words) for words in top_words_per_topic]\n",
    "\n",
    "# Print the refined labels in the desired format\n",
    "for idx, label in enumerate(topic_labels):\n",
    "    print(f\"Topic {idx}: \\\"{label}\\\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save topic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutting topic_labels text \"\"\n",
    "\n",
    "topic_labels = [label.replace('\"', '') for label in topic_labels]\n",
    "topic_labels\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(topic_labels)\n",
    "df.to_csv('../resources/topic_name.csv', index=False, encoding='utf-8')\n",
    "print(f\"Data saved to 'topic-name.csv'. Fetched {len(df)} results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save top_words_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_words_per_topic\n",
    "\n",
    "# data.head()\n",
    "df = pd.DataFrame(top_words_per_topic)\n",
    "# Save to CSV\n",
    "if not df.empty:\n",
    "    df.to_csv('../resources/cleaned_topicdata.csv', index=False, encoding='utf-8')\n",
    "    print(f\"Data saved to 'cleaned_topicdata.csv'. Fetched {len(df)} results.\")\n",
    "else:\n",
    "    print(\"No data fetched. Check the scraping process.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
